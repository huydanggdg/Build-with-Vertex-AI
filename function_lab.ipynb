#Enhance Gemini with access to external services with function calling: Challenge Lab

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "yjB9yzTQFIIaVS4VG9ilsJij",
   "metadata": {
    "id": "yjB9yzTQFIIaVS4VG9ilsJij",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m  WARNING: The script tb-gcp-uploader is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip3 install --upgrade --quiet --user google-cloud-aiplatform==1.88.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "vQjJjeW5UtFt",
   "metadata": {
    "id": "vQjJjeW5UtFt",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Restart kernel after installs so that your environment can access the new packages\n",
    "import IPython\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "OqGyIK3JUxaN",
   "metadata": {
    "id": "OqGyIK3JUxaN",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qwiklabs-gcp-00-fda1e3e5dd7e\n"
     ]
    }
   ],
   "source": [
    "import vertexai\n",
    "\n",
    "PROJECT_ID = ! gcloud config get-value project\n",
    "PROJECT_ID = PROJECT_ID[0]\n",
    "LOCATION = \"us-central1\" # @param {type:\"string\"}\n",
    "\n",
    "print(PROJECT_ID)\n",
    "\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "FK3sOWSKU0vQ",
   "metadata": {
    "id": "FK3sOWSKU0vQ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from vertexai.generative_models import (\n",
    "    Content,\n",
    "    FunctionDeclaration,\n",
    "    GenerationConfig,\n",
    "    GenerativeModel,\n",
    "    Part,\n",
    "    Tool,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "nM_FfDZQU3Vp",
   "metadata": {
    "id": "nM_FfDZQU3Vp",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: Define a function to reverse the order\n",
    "# of a string and return the result.\n",
    "# Keep the print statement within the function.\n",
    "def reverse(s: str) -> str:\n",
    "    \"\"\"Reverses the order of characters in a string.\"\"\"\n",
    "    print(\"Calling reverse function\")\n",
    "    return s[::-1]\n",
    "\n",
    "# TODO: Define a function to remove white space\n",
    "# characters from a string and return the result.\n",
    "# Keep the print statement within the function.\n",
    "def remove_white_spaces(s: str) -> str:\n",
    "    \"\"\"Removes all space characters from a string.\"\"\"\n",
    "    print(\"Calling remove_white_spaces function\")\n",
    "    return s.replace(\" \", \"\")\n",
    "\n",
    "def add(a: float, b: float) -> float:\n",
    "    \"\"\"Adds two numbers.\"\"\"\n",
    "    print(f\"Calling add function with {a} and {b}\")\n",
    "    return a + b\n",
    "\n",
    "def multiply(a: float, b: float) -> float:\n",
    "    \"\"\"Multiplies two numbers.\"\"\"\n",
    "    print(f\"Calling multiply function with {a} and {b}\")\n",
    "    return a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "kvsvuH7xU8c_",
   "metadata": {
    "id": "kvsvuH7xU8c_",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: Create FunctionDeclarations for your functions\n",
    "reverse_func_declaration = FunctionDeclaration(\n",
    "    name=\"reverse\",\n",
    "    description=\"Reverse the order of a string.\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"s\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"String to reverse\"\n",
    "            }\n",
    "        },\n",
    "         \"required\": [\"s\"]\n",
    "    },\n",
    ")\n",
    "\n",
    "remove_white_spaces_func_declaration = FunctionDeclaration(\n",
    "    name=\"remove_white_spaces\",\n",
    "    description=\"Remove space characters from a string.\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"s\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"String to remove spaces from\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"s\"]\n",
    "    },\n",
    ")\n",
    "\n",
    "add_func_declaration = FunctionDeclaration(\n",
    "    name=\"add\",\n",
    "    description=\"Add two numbers.\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"a\": {\"type\": \"number\", \"description\": \"The first number.\"},\n",
    "            \"b\": {\"type\": \"number\", \"description\": \"The second number.\"}\n",
    "        },\n",
    "        \"required\": [\"a\", \"b\"]\n",
    "    },\n",
    ")\n",
    "\n",
    "multiply_func_declaration = FunctionDeclaration(\n",
    "    name=\"multiply\",\n",
    "    description=\"Multiply two numbers.\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"a\": {\"type\": \"number\", \"description\": \"The first number.\"},\n",
    "            \"b\": {\"type\": \"number\", \"description\": \"The second number.\"}\n",
    "        },\n",
    "        \"required\": [\"a\", \"b\"]\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8Z-Ryih3U9xq",
   "metadata": {
    "id": "8Z-Ryih3U9xq",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the tools with the functions we created\n",
    "combined_tool = Tool(\n",
    "    function_declarations=[add_func_declaration, multiply_func_declaration, reverse_func_declaration, remove_white_spaces_func_declaration]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "wWkctUZCVBbO",
   "metadata": {
    "id": "wWkctUZCVBbO",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "model = GenerativeModel(\n",
    "    model_name=\"gemini-2.0-flash-001\",\n",
    "    generation_config=GenerationConfig(temperature=0),\n",
    "    system_instruction=[\n",
    "        \"Fulfill the user's instructions.\",\n",
    "        \"If asked to reverse a string or remove whitespace, call the provided functions.\",\n",
    "        \"You may call one function after the other if needed.\",\n",
    "        \"Repeat the result to the user.\",\n",
    "    ],\n",
    "    tools=[combined_tool],\n",
    ")\n",
    "\n",
    "# Initialize the chat model with tools and configuration\n",
    "chat = model.start_chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "KkUxWWRuVCo2",
   "metadata": {
    "id": "KkUxWWRuVCo2",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Functions, Declarations, Tool, Model, and handle_response function are now defined.\n"
     ]
    }
   ],
   "source": [
    "def handle_response(response):\n",
    "    \"\"\"Handles the model's response, executing function calls if necessary.\"\"\"\n",
    "    # Get the first part of the candidate's content\n",
    "    part = response.candidates[0].content.parts[0]\n",
    "\n",
    "    # Check if the model's response is a function call\n",
    "    if part.function_call:\n",
    "        function_call = part.function_call\n",
    "        \n",
    "        # if the function_call requests your reverse function\n",
    "        if function_call.name == \"reverse\":\n",
    "            # Extract the arguments to use in your function\n",
    "            args = {key: value for key, value in function_call.args.items()}\n",
    "            # Call your function\n",
    "            result = reverse(**args)\n",
    "            # Send the result back to the chat session with the model\n",
    "            response = chat.send_message(\n",
    "                Part.from_function_response(\n",
    "                    name=\"reverse\",\n",
    "                    response={\"content\": result},\n",
    "                )\n",
    "            )\n",
    "            # Recursive call\n",
    "            handle_response(response)\n",
    "    \n",
    "        # elif the function_call requests your remove_white_spaces function\n",
    "        elif function_call.name == \"remove_white_spaces\":\n",
    "            # Extract the arguments to use in your function\n",
    "            args = {key: value for key, value in function_call.args.items()}\n",
    "            # Call your function\n",
    "            result = remove_white_spaces(**args)\n",
    "            # Send the result back to the chat session with the model\n",
    "            response = chat.send_message(\n",
    "                Part.from_function_response(\n",
    "                    name=\"remove_white_spaces\",\n",
    "                    response={\"content\": result},\n",
    "                )\n",
    "            )\n",
    "            # Make a recursive call of this handler function\n",
    "            handle_response(response)\n",
    "            \n",
    "        elif function_call.name == \"add\":\n",
    "            # Extract the arguments to use in your function\n",
    "            args = {key: value for key, value in function_call.args.items()}\n",
    "            # Call your function\n",
    "            result = add(**args)\n",
    "            # Send the result back to the chat session with the model\n",
    "            response = chat.send_message(\n",
    "                Part.from_function_response(\n",
    "                    name=\"add\",\n",
    "                    response={\"content\": result},\n",
    "                )\n",
    "            )\n",
    "            # Make a recursive call of this handler function\n",
    "            handle_response(response)\n",
    "\n",
    "        elif function_call.name == \"multiply\":\n",
    "            # Extract the arguments to use in your function\n",
    "            args = {key: value for key, value in function_call.args.items()}\n",
    "            # Call your function\n",
    "            result = multiply(**args)\n",
    "            # Send the result back to the chat session with the model\n",
    "            response = chat.send_message(\n",
    "                Part.from_function_response(\n",
    "                    name=\"multiply\",\n",
    "                    response={\"content\": result},\n",
    "                )\n",
    "            )\n",
    "            # Make a recursive call of this handler function\n",
    "            handle_response(response)\n",
    "    \n",
    "        else:\n",
    "            # You shouldn't end up here\n",
    "            print(f\"Unknown function call: {function_call.name}\")\n",
    "    else:\n",
    "        # If there is no function call, print the text response.\n",
    "        print(part.text)\n",
    "        return\n",
    "\n",
    "print(\"Functions, Declarations, Tool, Model, and handle_response function are now defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "lf6PCMgRVFjS",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1608,
     "status": "ok",
     "timestamp": 1727538690146,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -180
    },
    "id": "lf6PCMgRVFjS",
    "outputId": "74f832ec-9360-4f01-e763-71152154a4e8",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why don't scientists trust atoms?\n",
      "\n",
      "Because they make up everything!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = chat.send_message(\"Tell me a joke.\")\n",
    "handle_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "mrfxtMw9VOye",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2286,
     "status": "ok",
     "timestamp": 1727538723569,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -180
    },
    "id": "mrfxtMw9VOye",
    "outputId": "84b69cd2-382b-47fc-c0aa-93081b408b83",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling reverse function\n",
      "dlrow olleH\n",
      "dlrow olleH\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = chat.send_message(\"Reverse the following string: Hello world\")\n",
    "handle_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "jGtzWeGPVSvC",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2009,
     "status": "ok",
     "timestamp": 1727538739560,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -180
    },
    "id": "jGtzWeGPVSvC",
    "outputId": "d037c56d-7695-47ca-e627-8be73c9d48e0",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling multiply function with 7 and 16\n",
      "You have 112 slices.\n",
      "You have 112 slices.\n"
     ]
    }
   ],
   "source": [
    "response = chat.send_message(\"I have 7 pizzas each with 16 slices. How many slices do I have?\")\n",
    "handle_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "DnC58jdOVVeE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3313,
     "status": "ok",
     "timestamp": 1727538751992,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -180
    },
    "id": "DnC58jdOVVeE",
    "outputId": "c4f65d2c-14aa-46d3-a94c-afd299ce8057",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling add function with 3 and 4\n",
      "They brought 7 pizzas together.\n",
      "They brought 7 pizzas together.\n"
     ]
    }
   ],
   "source": [
    "response = chat.send_message(\"Doug brought 3 pizzas. Andrew brought 4 pizzas. How many pizzas did they bring together?\")\n",
    "handle_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ab344dee-63da-428d-abe9-55f0964e4b16",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling add function with 3 and 4\n",
      "Calling multiply function with 7 and 16\n",
      "There are 112 slices.\n",
      "There are 112 slices.\n"
     ]
    }
   ],
   "source": [
    "response = chat.send_message(\"Doug brought 3 pizzas. Andrew brought 4 pizzas. There are 16 slices per pizza. How many slices are there?\")\n",
    "handle_response(response)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "JWDkN3v0VYWL",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3244,
     "status": "ok",
     "timestamp": 1727538763786,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -180
    },
    "id": "JWDkN3v0VYWL",
    "outputId": "2765d109-b5b0-408a-e372-9a0c8a6fd1e2",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling add function with 4 and -2\n",
      "There are 2 pizzas left.\n",
      "There are 2 pizzas left.\n"
     ]
    }
   ],
   "source": [
    "response = chat.send_message(\"Doug brought 4 pizzas, but Andrew dropped 2 on the ground. How many pizzas are left?\")\n",
    "handle_response(response) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "60a2dcdc-6d0f-4b91-8aa8-004b1ac5f1f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (3422157369.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[73], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    response = chat.send_message(Doug brought 4 pizzas, but Andrew dropped 2 on the ground. How many pizzas are left?)\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "response = chat.send_message(Doug brought 4 pizzas, but Andrew dropped 2 on the ground. How many pizzas are left?)\n",
    "handle_response(response) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c544cc77-b1ea-415f-82f9-603c40db7d3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Enhancing Large Language Models with Function Calling: A Gemini Case Study",
   "provenance": []
  },
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m131",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m131"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
